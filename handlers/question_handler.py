import logging
import re
from langchain.schema import HumanMessage
from langchain_openai import ChatOpenAI
from tools.gold_tool import get_gold_price
from tools.wiki_tool import get_wiki_summary
from rag.rag_agent import ask_rag
import os

llm = ChatOpenAI(
    model_name="gpt-3.5-turbo",
    temperature=0.7,
    openai_api_key=os.getenv("OPENAI_API_KEY")
)

def handle_gold_tool(question: str) -> str:
    logging.info("Using Gold Price Tool")
    return f"[ü™ô Gold] ‡∏£‡∏≤‡∏Ñ‡∏≤‡∏ó‡∏≠‡∏á‡∏Ñ‡∏≥‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠: {get_gold_price()}"

def handle_wiki_tool(question: str) -> str:
    logging.info("Using Wikipedia Tool")
    question = re.sub(r"(wiki(pedia)?[:Ôºö]?\s*)", "", question, flags=re.IGNORECASE)
    question = re.sub(r"(|‡∏Ñ‡∏∑‡∏≠‡πÉ‡∏Ñ‡∏£|‡∏≠‡∏¢‡∏π‡πà‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏≠‡∏∞‡πÑ‡∏£|‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö|‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Ç‡∏≠‡∏á|‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Ç‡∏≠‡∏á)", "", question, flags=re.IGNORECASE)
    cleaned_query = question.strip()

    summary = get_wiki_summary(cleaned_query)
    if "‡πÑ‡∏°‡πà‡∏û‡∏ö" in summary or len(summary.strip()) == 0:
        return f"[üåê Wiki] ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô Wikipedia ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö '{cleaned_query}'"
    return f"[üåê Wiki] ‡∏™‡∏£‡∏∏‡∏õ‡∏à‡∏≤‡∏Å Wikipedia: {summary}"

def handle_rag_tool(question: str) -> str:
    logging.info("Using RAG Tool")
    return f"[üìÑ RAG] {ask_rag(question)}"

def handle_general_gpt(question: str) -> str:
    logging.info("Using GPT-3.5 Fallback")
    response = llm.invoke([
        HumanMessage(content=f"‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°‡∏ß‡πà‡∏≤: {question} ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏ï‡∏≠‡∏ö‡πÅ‡∏ö‡∏ö‡∏°‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û")
    ])
    return f"ü§ñ GPT-3.5: {response.content}"
